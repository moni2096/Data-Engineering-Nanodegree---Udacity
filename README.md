 ![Language](https://img.shields.io/badge/language-python--3.8-blue) [![Contributors][contributors-shield]][contributors-url] [![Forks][forks-shield]][forks-url] [![Stargazers][stars-shield]][stars-url] [![Issues][issues-shield]][issues-url] [![MIT License][license-shield]][license-url] [![LinkedIn][linkedin-shield]][linkedin-url]

# Introduction
This repository contains my implementation of projects involved in Data Engineering Nanodegree by Udacity.

<img src="https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/blob/main/Certificate.png" width="1000"/>

# Getting Started
The program has 5 hands on projects and one capstone project.

 1. [**Data Modeling with Postgres**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/1.%20Data%20Modeling%20with%20Postgres%20and%20Apache%20Cassandra/Data%20Modeling%20with%20Postgres): In this project, we modeled data for a music streaming company called Sparkify by choosing appropriate modeling schema and data types to model tables for setting up analytics workflow in Postgres.
 2. [**Data Modeling in Apache Cassandra**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/1.%20Data%20Modeling%20with%20Postgres%20and%20Apache%20Cassandra/Data%20Modeling%20with%20Apache%20Cassandra): As we know in Apache Cassandra the tables are modeled as per the queries that we are going to write we followed similar workflow to model tables for some queries using Apache Cassandra.
 3. [**Cloud Data Warehouse**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/2.%20Cloud%20Data%20Warehouses): In this project we model tables using Amazon Redshift using the same schema that we used in Project 1 since the requirements of the analytics workflow and scaling needs for the company Sparkify changed.
 4. [**Data Lakes with Spark**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/3.%20Data%20Lakes%20with%20Spark): In this project we get to understand the importance of Data Lakes and its importance to address the specific needs that an organization might have where Data Lakes might be a good choice to be considered.
 5. [**Data Pipelines with Airflow**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/4.%20Data%20Pipelines%20with%20Airflow): In this project we learn how to ingest data on scheduled basis when the data size grows and ingestion of data on a particular interval is important for an Organization. We model tables in redshift and use Airflow to schedule ingestion into the table at particular interval. We also consider the use case where a downstream report can be generated using Airflow by designing pipeline. 
6. [**Capstone Project**](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/5.%20Capstone%20Project): In this project we combine what we learn and put into practice by solving a real world data proble. Here, I have built a data pipeline using AWS to ingest CryptoCurrency data from API and other sources.

## License
Distributed under the MIT License. See `LICENSE` for more information.





