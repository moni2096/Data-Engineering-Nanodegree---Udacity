# Introduction
This repository contains my implementation of projects involved in Data Engineering Nanodegree by Udacity.

# Getting Started
The program has 5 hands on projects and one capstone project. The 5 capstone projects are:

 1. **Data Modeling with Postgres**: In this project, we modeled data for a music streaming company called Sparkify by choosing appropriate modeling schema and data types to model tables for setting up analytics workflow in Postgres. The details and code files associated with this projects are found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/1.%20Data%20Modeling%20with%20Postgres%20and%20Apache%20Cassandra/Data%20Modeling%20with%20Postgres)
 2. **Data Modeling in Apache Cassandra**: As we know in Apache Cassandra the tables are modeled as per the queries that we are going to write we followed similar workflow to model tables for some queries using Apache Cassandra. The entire process is depicted in this notebook and the code files can be found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/1.%20Data%20Modeling%20with%20Postgres%20and%20Apache%20Cassandra/Data%20Modeling%20with%20Apache%20Cassandra)
 3. **Cloud Data Warehouse**: In this project we model tables using Amazon Redshift using the same schema that we used in Project 1 since the requirements of the analytics workflow and scaling needs for the company Sparkify changed. The code files and instruction to get started can be found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/2.%20Cloud%20Data%20Warehouses)
 4. **Data Lakes with Spark**: In this project we get to understand the importance of Data Lakes and its importance to address the specific needs that an organization might have where Data Lakes might be a good choice to be considered. We model table using Spark from data store in S3 bucket. The code files and instructions to run this project can be found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/3.%20Data%20Lakes%20with%20Spark)
 5. **Data Pipelines with Airflow**: In this project we learn how to ingest data on scheduled basis when the data size grows and ingestion of data on a particular interval is important for an Organization. We model tables in redshift and use Airflow to schedule ingestion into the table at particular interval. We also consider the use case where a downstream report can be generated using Airflow by designing pipeline. The code files can be found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/4.%20Data%20Pipelines%20with%20Airflow)
6. **Capstone Project**: In this project we combine what we learn and put into practice by solving a real world data proble. Here, I have built a data pipeline using AWS to ingest CryptoCurrency data from API and other sources. The details for this project and code files can be found [here](https://github.com/moni2096/Data-Engineering-Nanodegree-Udacity/tree/main/5.%20Capstone%20Project)	


